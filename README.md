# ğŸ’»Projeto Datalake com Spark
- Este projeto demonstra a anÃ¡lise de vendas usando PySpark dentro de um contÃªiner Docker. 
- O objetivo Ã© criar um DataFrame com um volume significativo de dados, realizar operaÃ§Ãµes de agregaÃ§Ã£o e exibir os resultados. 
- O ambiente de execuÃ§Ã£o Ã© isolado e replicÃ¡vel, utilizando Docker.


>**Grupo (Cascas de Bala)**
> 1. Dyelle Hemylle Nunes de Almeida
> 2. Ingrid Gabrielly Camara Lira
> 3. Jarmison Kecio Ferreira da Cunha
> 4. Kleber Lucas Lopes Alves
> 5. TÃ¡llyson Emanoel Roques Izidio
> 6. Vitor Eduardo de Carvalho

## âœ…PrÃ©-requisitos
- Docker instalado na sua mÃ¡quina. 
- [Site oficial](https://www.docker.com/)
para baixar e instalar o Docker.

## â™Ÿï¸Estrutura do Projeto

```datalake-spark-project/
â”œâ”€â”€ app/
â”‚ â””â”€â”€ app.py
â””â”€â”€ Dockerfile
â””â”€â”€ README.md
â””â”€â”€ package-lock.json
```

## âœ…Construir imagem
Para construir a imagem Docker, execute o seguinte comando no diretÃ³rio raiz do projeto (datalake-spark-project):
```bash
docker build -t datalake:latest .
```


## âœ…Executar
Para executar o contÃªiner Docker com a imagem construÃ­da, use o comando:
```
docker run datalake
```

# ğŸ“„DocumentaÃ§Ã£o do Projeto

## DependÃªncias do Projeto

Este projeto depende das seguintes tecnologias e bibliotecas:

- **Apache Spark**: uma estrutura de computaÃ§Ã£o distribuÃ­da para processamento de dados em grande escala.
- **PySpark**: a API Python para Apache Spark, permitindo a manipulaÃ§Ã£o de grandes conjuntos de dados.
- **Docker**: uma plataforma para desenvolver, enviar e executar aplicaÃ§Ãµes em contÃªineres.

### InstalaÃ§Ã£o de DependÃªncias

Certifique-se de que as seguintes dependÃªncias estÃ£o instaladas na sua mÃ¡quina:

1. **Docker**:
   - Siga as instruÃ§Ãµes de instalaÃ§Ã£o no [site oficial do Docker](https://www.docker.com/).

2. **Python** (opcional, apenas se vocÃª quiser executar os scripts localmente sem Docker):
   - Instale a versÃ£o mais recente do Python a partir do [site oficial do Python](https://www.python.org/downloads/).
   - Instale o PySpark usando o pip:
     ```bash
     pip install pyspark
     ```

## Scripts e Programas
Esta seÃ§Ã£o detalha os scripts e programas incluÃ­dos neste projeto, explicando sua funcionalidade e estrutura.
```
app.py:
``` 
- Este script realiza a anÃ¡lise de vendas utilizando PySpark. 
- Ele cria um DataFrame com dados de produtos, quantidade e preÃ§o, calcula a receita total e a mÃ©dia de vendas por produto, e exibe os resultados.
- Inicializa a sessÃ£o do Spark para processar dados.

```
Dockerfile:
``` 
- Configura o ambiente necessÃ¡rio para executar o script app.py em um contÃªiner Docker. 
- Instala Python e bibliotecas necessÃ¡rias.
- Define o diretÃ³rio de trabalho e copia os arquivos do projeto.
- O contÃªiner executa app.py ao iniciar.

## ExecuÃ§Ã£o Local (Opcional)

Se vocÃª preferir executar o script localmente sem usar Docker, vocÃª pode seguir estas etapas:

1. Certifique-se de que o PySpark estÃ¡ instalado (como mencionado anteriormente).
2. Navegue atÃ© o diretÃ³rio onde o `app.py` estÃ¡ localizado.
3. Execute o script usando o comando:
   ```bash
   python app/app.py

## Exemplo de SaÃ­da
ApÃ³s executar o contÃªiner ou o script localmente, vocÃª verÃ¡ uma saÃ­da semelhante a esta:

| Produto  | Quantidade | Preco| 
| ------------- | ------------- | ------------- | 
| Produto1  | 1 | 150 |
| Produto2  | 2 | 250 |
| Produto3  | 3 | 350 |
| ... | ... | ... |

### Receita Total por Produto:
| Produto  | Receita_Total |
| ------------- | ------------- | 
| Produto9  | 2755000 |
| Produto8  | 2380000 | 
| Produto5  | 1375000 | 
| ... | ... |

### MÃ©dia de Vendas por Produto:
| Produto  | Media_Vendas |
| ------------- | ------------- | 
| Produto9  |  27550.0 |
| Produto8  | 23800.0 | 
| Produto5  | 13750.0 | 
| ... | ... |
## Como o Projeto Funciona
1. **InicializaÃ§Ã£o da SparkSession:** o script comeÃ§a criando uma SparkSession, que Ã© a entrada principal para a funcionalidade de Spark.
2. **CriaÃ§Ã£o do DataFrame:** gera um DataFrame com 1000 registros, cada um representando vendas de diferentes produtos.
3. **OperaÃ§Ãµes de AgregaÃ§Ã£o:** o script calcula a receita total e a mÃ©dia de vendas por produto, utilizando funÃ§Ãµes de agregaÃ§Ã£o do PySpark.
4. **ExibiÃ§Ã£o dos Resultados:** os resultados das operaÃ§Ãµes de agregaÃ§Ã£o sÃ£o exibidos no console.
5. **ExecuÃ§Ã£o em Docker:** o projeto Ã© executado dentro de um contÃªiner Docker para garantir um ambiente consistente e replicÃ¡vel.

## BenefÃ­cios do Uso de Docker
1. **Isolamento de Ambiente:** Docker fornece um ambiente de execuÃ§Ã£o isolado, garantindo que as dependÃªncias e configuraÃ§Ãµes sejam consistentes em diferentes mÃ¡quinas.
2. **Reprodutibilidade:** o uso de contÃªineres garante que o cÃ³digo funcione da mesma maneira em qualquer mÃ¡quina, eliminando problemas de "funciona na minha mÃ¡quina".
3. **Facilidade de DistribuiÃ§Ã£o:** compartilhar o contÃªiner Docker com outras pessoas permite que elas executem o projeto sem precisar configurar o ambiente manualmente.